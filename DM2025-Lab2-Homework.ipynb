{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Student Information**\n",
    "Name: 蔡明偉\n",
    "\n",
    "Student ID: 114062424\n",
    "\n",
    "GitHub ID: william-code87\n",
    "\n",
    "Kaggle name: williamia\n",
    "\n",
    "Kaggle private scoreboard snapshot: \n",
    "\n",
    "![pic_ranking.png](./pics/pic_ranking.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Instructions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we have divided the assignments into **three phases/parts**. The `first two phases` refer to the `exercises inside the Master notebooks` of the [DM2025-Lab2-Exercise Repo](https://github.com/difersalest/DM2025-Lab2-Exercise.git). The `third phase` refers to an `internal Kaggle competition` that we are gonna run among all the Data Mining students. Together they add up to `100 points` of your grade. There are also some `bonus points` to be gained if you complete `extra exercises` in the lab **(bonus 15 pts)** and in the `Kaggle Competition report` **(bonus 5 pts)**.\n",
    "\n",
    "**Environment recommendations to solve lab 2:**\n",
    "- **Phase 1 exercises:** Need GPU for training the models explained in that part, if you don't have a GPU in your laptop it is recommended to run in Colab or Kaggle for a faster experience, although with CPU they can still be solved but with a slower execution.\n",
    "- **Phase 2 exercises:** We use Gemini's API so everything can be run with only CPU without a problem.\n",
    "- **Phase 3 exercises:** For the competition you will probably need GPU to train your models, so it is recommended to use Colab or Kaggle if you don't have a laptop with a dedicated GPU.\n",
    "- **Optional Ollama Notebook (not graded):** You need GPU, at least 4GB of VRAM with 16 GB of RAM to run the local open-source LLM models. \n",
    "\n",
    "## **Phase 1 (30 pts):**\n",
    "\n",
    "1. __Main Exercises (25 pts):__ Do the **take home exercises** from Sections: `1. Data Preparation` to `9. High-dimension Visualization: t-SNE and UMAP`, in the [DM2025-Lab2-Master-Phase_1 Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_1.ipynb). Total: `8 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 3th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "## **Phase 2 (30 pts):**\n",
    "\n",
    "1. **Main Exercises (25 pts):** Do the remaining **take home exercises** from Section: `2. Large Language Models (LLMs)` in the [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb). Total: `5 exercises required from sections 2.1, 2.2, 2.4 and 2.6`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "2. **Code Comments (5 pts):** **Tidy up the code in your notebook**. \n",
    "\n",
    "3. **`Bonus (15 pts):`** Complete the bonus exercises in the [DM2025-Lab2-Master-Phase_2_Bonus Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Bonus.ipynb) and [DM2025-Lab2-Master-Phase_2_Main Notebook](https://github.com/difersalest/DM2025-Lab2-Exercise/blob/main/DM2025-Lab2-Master-Phase_2_Main.ipynb) `where 2 exercises are counted as bonus from sections 2.3 and 2.5 in the main notebook`. Total: `7 exercises`. Commit your code and submit the repository link to NTU Cool **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**\n",
    "\n",
    "## **Phase 3 (40 pts):**\n",
    "\n",
    "1. **Kaggle Competition Participation (30 pts):** Participate in the in-class **Kaggle Competition** regarding Emotion Recognition on Twitter by clicking in this link: **[Data Mining Class Kaggle Competition](https://www.kaggle.com/competitions/dm-lab-2-private-competition)**. The scoring will be given according to your place in the Private Leaderboard ranking: \n",
    "    - **Bottom 40%**: Get 20 pts of the 30 pts in this competition participation part.\n",
    "\n",
    "    - **Top 41% - 100%**: Get (0.6N + 1 - x) / (0.6N) * 10 + 20 points, where N is the total number of participants, and x is your rank. (ie. If there are 100 participants and you rank 3rd your score will be (0.6 * 100 + 1 - 3) / (0.6 * 100) * 10 + 20 = 29.67% out of 30%.)   \n",
    "    Submit your last submission **`BEFORE the deadline (Nov. 24th, 11:59 pm, Monday)`**. Make sure to take a screenshot of your position at the end of the competition and store it as `pic_ranking.png` under the `pics` folder of this repository and rerun the cell **Student Information**.\n",
    "\n",
    "2. **Competition Report (10 pts)** A report section to be filled in inside this notebook in Markdown Format, we already provided you with the template below. You need to describe your work developing the model for the competition. The report should include a section describing briefly the following elements: \n",
    "* Your preprocessing steps.\n",
    "* The feature engineering steps.\n",
    "* Explanation of your model.\n",
    "\n",
    "* **`Bonus (5 pts):`**\n",
    "    * You will have to describe more detail in the previous steps.\n",
    "    * Mention different things you tried.\n",
    "    * Mention insights you gained. \n",
    "\n",
    "[Markdown Guide - Basic Syntax](https://www.markdownguide.org/basic-syntax/)\n",
    "\n",
    "**`Things to note for Phase 3:`**\n",
    "\n",
    "* **The code used for the competition should be in this Jupyter Notebook File** `DM2025-Lab2-Homework.ipynb`.\n",
    "\n",
    "* **Push the code used for the competition to your repository**.\n",
    "\n",
    "* **The code should have a clear separation for the same sections of the report, preprocessing, feature engineering and model explanation. Briefly comment your code for easier understanding, we provide a template at the end of this notebook.**\n",
    "\n",
    "* Showing the kaggle screenshot of the ranking plus the code in this notebook will ensure the validity of your participation and the report to obtain the corresponding points.\n",
    "\n",
    "After the competition ends you will have two days more to submit the `DM2025-Lab2-Homework.ipynb` with your report in markdown format and your code. Do everything **`BEFORE the deadline (Nov. 26th, 11:59 pm, Wednesday) to obtain 100% of the available points.`**\n",
    "\n",
    "Upload your files to your repository then submit the link to it on the corresponding NTU Cool assignment.\n",
    "\n",
    "## **Deadlines:**\n",
    "\n",
    "![lab2_deadlines](./pics/lab2_deadlines.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Next you will find the template report with some simple markdown syntax explanations, use it to structure your content.\n",
    "\n",
    "You can delete the syntax suggestions after you use them.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "# **Project Report**\n",
    "\n",
    "**Syntax:** `#` creates the largest heading (H1).\n",
    "\n",
    "---\n",
    "**Syntax:** `---` creates a horizontal rule (a separator line).\n",
    "\n",
    "## 1. Model Development (10 pts Required)\n",
    "\n",
    "**Syntax:** `##` creates a secondary heading (H2).\n",
    "\n",
    "**Describe briefly each section, you can add graphs/charts to support your explanations.**\n",
    "\n",
    "## I wrote my report on pdf file. ## \n",
    "\n",
    "---\n",
    "\n",
    "## 2. Bonus Section (5 pts Optional)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`From here on starts the code section for the competition.`**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Competition Code**\n",
    "\n",
    "## 1. Preprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train/test...\n",
      "Train size: 47890, Test size: 16281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/114062424/dm_competition/myenv/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 47890/47890 [00:03<00:00, 14678.98 examples/s]\n",
      "Map: 100%|██████████| 16281/16281 [00:01<00:00, 12275.26 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import os, re, gc, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    DataCollatorWithPadding,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "# CONFIG\n",
    "\n",
    "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
    "MAX_LEN = 192\n",
    "\n",
    "TRAIN_CSV = \"train.csv\"\n",
    "TEST_CSV = \"test.csv\"\n",
    "\n",
    "CV5_DIR = \"cv5_deberta_v3_base\"\n",
    "PSEUDO_DIR = \"deberta_v3_pseudo_final\"\n",
    "\n",
    "os.makedirs(CV5_DIR, exist_ok=True)\n",
    "os.makedirs(PSEUDO_DIR, exist_ok=True)\n",
    "\n",
    "EMOTIONS = [\"joy\", \"fear\", \"anger\", \"surprise\", \"sadness\", \"disgust\"]\n",
    "label2id = {e: i for i, e in enumerate(EMOTIONS)}\n",
    "id2label = {i: e for e, i in label2id.items()}\n",
    "\n",
    "N_FOLDS = 5\n",
    "SEED = 42\n",
    "\n",
    "PSEUDO_THRESHOLD = 0.90\n",
    "ALPHA_CV5 = 0.7   \n",
    "\n",
    "\n",
    "# UTIL\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    set_seed(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "URL_RE = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "USER_RE = re.compile(r\"@\\w+\")\n",
    "ELONG_RE = re.compile(r\"(.)\\1{3,}\")\n",
    "MULTI_WS = re.compile(r\"\\s+\")\n",
    "\n",
    "def clean_text(t: str) -> str:\n",
    "    t = str(t)\n",
    "    t = URL_RE.sub(\"<url>\", t)\n",
    "    t = USER_RE.sub(\"<user>\", t)\n",
    "    t = ELONG_RE.sub(r\"\\1\\1\\1\", t)\n",
    "    t = MULTI_WS.sub(\" \", t).strip()\n",
    "    return t\n",
    "\n",
    "def compute_metrics_eval(pred):\n",
    "    logits = pred.predictions\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_macro\": f1_score(labels, preds, average=\"macro\"),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "# LOAD DATA\n",
    "\n",
    "print(\"Loading train/test...\")\n",
    "df_train = pd.read_csv(TRAIN_CSV)\n",
    "df_test = pd.read_csv(TEST_CSV)\n",
    "\n",
    "assert {\"id\", \"text\", \"emotion\"}.issubset(df_train.columns)\n",
    "assert {\"id\", \"text\"}.issubset(df_test.columns)\n",
    "\n",
    "df_train = df_train.dropna(subset=[\"text\", \"emotion\"]).copy()\n",
    "df_train[\"text\"] = df_train[\"text\"].map(clean_text)\n",
    "df_train[\"emotion\"] = df_train[\"emotion\"].astype(str).str.strip()\n",
    "df_train = df_train[df_train[\"emotion\"].isin(EMOTIONS)].copy()\n",
    "df_train[\"labels\"] = df_train[\"emotion\"].map(label2id)\n",
    "\n",
    "df_test = df_test.dropna(subset=[\"text\"]).copy()\n",
    "df_test[\"text\"] = df_test[\"text\"].map(clean_text)\n",
    "\n",
    "num_train = len(df_train)\n",
    "num_test = len(df_test)\n",
    "print(f\"Train size: {num_train}, Test size: {num_test}\")\n",
    "\n",
    "# TOKENIZER\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "# Full train dataset (for CV split)\n",
    "full_ds = Dataset.from_pandas(\n",
    "    df_train[[\"id\", \"text\", \"labels\"]].copy(), preserve_index=False\n",
    ")\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=MAX_LEN,\n",
    "    )\n",
    "\n",
    "full_ds = full_ds.map(tokenize_fn, batched=True)\n",
    "full_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "# Test dataset tokenized (for CV prediction and later)\n",
    "hf_test = Dataset.from_pandas(df_test[[\"id\", \"text\"]].copy(), preserve_index=False)\n",
    "hf_test = hf_test.map(tokenize_fn, batched=True)\n",
    "hf_test = hf_test.remove_columns([\"id\", \"text\"])\n",
    "hf_test.set_format(type=\"torch\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP A] CV5 logits already exist. Loading from disk...\n",
      "\n",
      "[STEP B] Pseudo-labeling high-confidence test samples...\n",
      "Total test samples: 16281\n",
      "Pseudo-label selected (p >= 0.9): 7218\n",
      "Pseudo-label distribution:\n",
      "emotion\n",
      "joy         4969\n",
      "anger       1489\n",
      "surprise     439\n",
      "fear         297\n",
      "sadness       24\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Combined train+pseudo size: 55108\n"
     ]
    }
   ],
   "source": [
    "# CV5 DeBERTa-v3-base (if not already saved)\n",
    "\n",
    "cv5_oof_path = os.path.join(CV5_DIR, \"oof_logits.npy\")\n",
    "cv5_test_path = os.path.join(CV5_DIR, \"test_logits.npy\")\n",
    "\n",
    "if os.path.exists(cv5_oof_path) and os.path.exists(cv5_test_path):\n",
    "    print(\"\\n[STEP A] CV5 logits already exist. Loading from disk...\")\n",
    "    oof_logits = np.load(cv5_oof_path)\n",
    "    cv5_test_logits = np.load(cv5_test_path)\n",
    "else:\n",
    "    print(\"\\n[STEP A] Running 5-Fold CV training with DeBERTa-v3-base...\")\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "    oof_logits = np.zeros((num_train, len(EMOTIONS)), dtype=np.float32)\n",
    "    test_logits_accum = np.zeros((num_test, len(EMOTIONS)), dtype=np.float32)\n",
    "\n",
    "    labels_np = df_train[\"labels\"].values\n",
    "\n",
    "    fold_idx = 0\n",
    "    for tr_idx, val_idx in skf.split(np.zeros(num_train), labels_np):\n",
    "        fold_idx += 1\n",
    "        print(f\"\\n===== FOLD {fold_idx}/{N_FOLDS} =====\")\n",
    "        print(f\"Train idx: {len(tr_idx)}, Val idx: {len(val_idx)}\")\n",
    "\n",
    "        ds_tr = full_ds.select(tr_idx.tolist())\n",
    "        ds_val = full_ds.select(val_idx.tolist())\n",
    "\n",
    "        # Reload model each fold\n",
    "        print(\"Loading model:\", MODEL_NAME)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            MODEL_NAME,\n",
    "            num_labels=len(EMOTIONS),\n",
    "            id2label=id2label,\n",
    "            label2id=label2id,\n",
    "        )\n",
    "\n",
    "        if hasattr(model.config, \"classifier_dropout\"):\n",
    "            model.config.classifier_dropout = 0.10\n",
    "        if hasattr(model.config, \"hidden_dropout_prob\"):\n",
    "            model.config.hidden_dropout_prob = 0.10\n",
    "        if hasattr(model.config, \"attention_probs_dropout_prob\"):\n",
    "            model.config.attention_probs_dropout_prob = 0.10\n",
    "        if hasattr(model.config, \"use_cache\"):\n",
    "            model.config.use_cache = False\n",
    "\n",
    "\n",
    "        output_dir_fold = os.path.join(CV5_DIR, f\"fold_{fold_idx}\")\n",
    "        os.makedirs(output_dir_fold, exist_ok=True)\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            output_dir=output_dir_fold,\n",
    "            learning_rate=2e-5,\n",
    "            per_device_train_batch_size=4,\n",
    "            per_device_eval_batch_size=8,\n",
    "            gradient_accumulation_steps=4,\n",
    "            num_train_epochs=4,\n",
    "            warmup_ratio=0.1,\n",
    "            weight_decay=0.01,\n",
    "            max_grad_norm=1.0,\n",
    "            lr_scheduler_type=\"cosine\",\n",
    "            eval_strategy=\"steps\",\n",
    "            eval_steps=1500,\n",
    "            save_strategy=\"steps\",\n",
    "            save_steps=1500,\n",
    "            save_total_limit=1,\n",
    "            load_best_model_at_end=True,\n",
    "            metric_for_best_model=\"f1_weighted\",\n",
    "            greater_is_better=True,\n",
    "            fp16=True,\n",
    "            logging_steps=200,\n",
    "            report_to=\"none\",\n",
    "            dataloader_num_workers=2,\n",
    "            save_safetensors=True,\n",
    "        )\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model=model,\n",
    "            args=args,\n",
    "            train_dataset=ds_tr,\n",
    "            eval_dataset=ds_val,\n",
    "            data_collator=collator,\n",
    "            compute_metrics=compute_metrics_eval,\n",
    "        )\n",
    "\n",
    "        trainer.train()\n",
    "\n",
    "        # Predict on validation fold\n",
    "        val_pred = trainer.predict(ds_val)\n",
    "        val_logits = val_pred.predictions\n",
    "        oof_logits[val_idx] = val_logits\n",
    "\n",
    "        # Predict on test\n",
    "        test_pred = trainer.predict(hf_test)\n",
    "        test_logits_accum += test_pred.predictions\n",
    "\n",
    "        # cleanup\n",
    "        del model, trainer, ds_tr, ds_val, val_pred, test_pred\n",
    "        gc.collect()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    cv5_test_logits = test_logits_accum / N_FOLDS\n",
    "\n",
    "    # Eval OOF\n",
    "    oof_preds = oof_logits.argmax(axis=-1)\n",
    "    y_true = df_train[\"labels\"].values\n",
    "\n",
    "    print(\"\\n========== 5-FOLD OOF EVALUATION ==========\")\n",
    "    print(\"\\n=== OOF Validation Metrics ===\")\n",
    "    print(f\"Accuracy     : {accuracy_score(y_true, oof_preds):.4f}\")\n",
    "    print(f\"F1 Weighted  : {f1_score(y_true, oof_preds, average='weighted'):.4f}\")\n",
    "    print(f\"F1 Macro     : {f1_score(y_true, oof_preds, average='macro'):.4f}\")\n",
    "    print(\"\\n=== OOF Classification Report ===\")\n",
    "    print(classification_report(y_true, oof_preds, target_names=EMOTIONS, digits=4))\n",
    "    print(\"\\n=== OOF Confusion Matrix ===\")\n",
    "    print(confusion_matrix(y_true, oof_preds))\n",
    "\n",
    "    # Save logits\n",
    "    np.save(cv5_oof_path, oof_logits)\n",
    "    np.save(cv5_test_path, cv5_test_logits)\n",
    "    print(f\"\\n[INFO] Saved OOF logits to: {cv5_oof_path}\")\n",
    "    print(f\"[INFO] Saved test logits to: {cv5_test_path}\")\n",
    "\n",
    "# Pseudo-label high-confidence test samples\n",
    "\n",
    "print(\"\\n[STEP B] Pseudo-labeling high-confidence test samples...\")\n",
    "cv5_test_probs = torch.softmax(torch.tensor(cv5_test_logits), dim=-1).numpy()\n",
    "max_prob = cv5_test_probs.max(axis=-1)\n",
    "pseudo_ids = np.where(max_prob >= PSEUDO_THRESHOLD)[0]\n",
    "\n",
    "print(f\"Total test samples: {len(cv5_test_probs)}\")\n",
    "print(f\"Pseudo-label selected (p >= {PSEUDO_THRESHOLD}): {len(pseudo_ids)}\")\n",
    "\n",
    "pseudo_labels = cv5_test_probs[pseudo_ids].argmax(axis=-1)\n",
    "pseudo_emotions = [id2label[i] for i in pseudo_labels]\n",
    "\n",
    "pseudo_df = pd.DataFrame({\n",
    "    \"id\": df_test.iloc[pseudo_ids][\"id\"].values,\n",
    "    \"text\": df_test.iloc[pseudo_ids][\"text\"].values,\n",
    "    \"emotion\": pseudo_emotions,\n",
    "})\n",
    "pseudo_df[\"labels\"] = pseudo_df[\"emotion\"].map(label2id)\n",
    "\n",
    "print(\"Pseudo-label distribution:\")\n",
    "print(pseudo_df[\"emotion\"].value_counts())\n",
    "\n",
    "# Combine original train + pseudo\n",
    "train_pseudo_df = pd.concat(\n",
    "    [df_train[[\"id\", \"text\", \"emotion\", \"labels\"]], pseudo_df],\n",
    "    ignore_index=True\n",
    ")\n",
    "print(f\"\\nCombined train+pseudo size: {len(train_pseudo_df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Implementation Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[STEP C] Training final DeBERTa-v3-base on train+pseudo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/49597 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 49597/49597 [00:03<00:00, 12901.55 examples/s]\n",
      "Map: 100%|██████████| 5511/5511 [00:00<00:00, 14500.51 examples/s]\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='12400' max='12400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [12400/12400 1:21:04, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.838727</td>\n",
       "      <td>0.711849</td>\n",
       "      <td>0.479161</td>\n",
       "      <td>0.697949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.806100</td>\n",
       "      <td>0.799667</td>\n",
       "      <td>0.720377</td>\n",
       "      <td>0.522365</td>\n",
       "      <td>0.708003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.696200</td>\n",
       "      <td>0.768931</td>\n",
       "      <td>0.737071</td>\n",
       "      <td>0.540241</td>\n",
       "      <td>0.721895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.700100</td>\n",
       "      <td>0.812577</td>\n",
       "      <td>0.732898</td>\n",
       "      <td>0.543454</td>\n",
       "      <td>0.723880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.586400</td>\n",
       "      <td>0.789951</td>\n",
       "      <td>0.737979</td>\n",
       "      <td>0.575704</td>\n",
       "      <td>0.728310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.571400</td>\n",
       "      <td>0.795899</td>\n",
       "      <td>0.741971</td>\n",
       "      <td>0.575693</td>\n",
       "      <td>0.736889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.452400</td>\n",
       "      <td>0.866979</td>\n",
       "      <td>0.738523</td>\n",
       "      <td>0.573410</td>\n",
       "      <td>0.733888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.449100</td>\n",
       "      <td>0.860024</td>\n",
       "      <td>0.737253</td>\n",
       "      <td>0.570764</td>\n",
       "      <td>0.732688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PSEUDO-FINAL MODEL Validation Metrics ===\n",
      "Accuracy     : 0.7420\n",
      "F1 Weighted  : 0.7369\n",
      "F1 Macro     : 0.5757\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         joy     0.8435    0.8596    0.8514      2877\n",
      "        fear     0.6270    0.6623    0.6442       231\n",
      "       anger     0.6685    0.7102    0.6887      1218\n",
      "    surprise     0.6256    0.5967    0.6108       672\n",
      "     sadness     0.5184    0.4633    0.4893       395\n",
      "     disgust     0.2979    0.1186    0.1697       118\n",
      "\n",
      "    accuracy                         0.7420      5511\n",
      "   macro avg     0.5968    0.5685    0.5757      5511\n",
      "weighted avg     0.7342    0.7420    0.7369      5511\n",
      "\n",
      "[INFO] Saved pseudo val logits to: deberta_v3_pseudo_final/val_logits.npy\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved pseudo test logits to: deberta_v3_pseudo_final/test_logits.npy\n",
      "\n",
      "[STEP D] Final ensemble & submission...\n",
      "\n",
      "[INFO] Saved FINAL submission to: final_submission.csv\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Train final SINGLE model on train+pseudo\n",
    "\n",
    "pseudo_val_logits_path = os.path.join(PSEUDO_DIR, \"val_logits.npy\")\n",
    "pseudo_test_logits_path = os.path.join(PSEUDO_DIR, \"test_logits.npy\")\n",
    "\n",
    "if os.path.exists(pseudo_val_logits_path) and os.path.exists(pseudo_test_logits_path):\n",
    "    print(\"\\n[STEP C] Pseudo final model logits already exist. Loading...\")\n",
    "    pseudo_val_logits = np.load(pseudo_val_logits_path)\n",
    "    pseudo_test_logits = np.load(pseudo_test_logits_path)\n",
    "else:\n",
    "    print(\"\\n[STEP C] Training final DeBERTa-v3-base on train+pseudo...\")\n",
    "\n",
    "    # Split small validation from combined train\n",
    "    tr_df, val_df = train_test_split(\n",
    "        train_pseudo_df,\n",
    "        test_size=0.10,\n",
    "        random_state=SEED,\n",
    "        stratify=train_pseudo_df[\"emotion\"],\n",
    "    )\n",
    "\n",
    "    tr_ds = Dataset.from_pandas(tr_df[[\"id\", \"text\", \"labels\"]].copy(), preserve_index=False)\n",
    "    val_ds = Dataset.from_pandas(val_df[[\"id\", \"text\", \"labels\"]].copy(), preserve_index=False)\n",
    "\n",
    "    tr_ds = tr_ds.map(tokenize_fn, batched=True)\n",
    "    val_ds = val_ds.map(tokenize_fn, batched=True)\n",
    "    tr_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "    val_ds.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        num_labels=len(EMOTIONS),\n",
    "        id2label=id2label,\n",
    "        label2id=label2id,\n",
    "    )\n",
    "\n",
    "    if hasattr(model.config, \"classifier_dropout\"):\n",
    "        model.config.classifier_dropout = 0.10\n",
    "    if hasattr(model.config, \"hidden_dropout_prob\"):\n",
    "        model.config.hidden_dropout_prob = 0.10\n",
    "    if hasattr(model.config, \"attention_probs_dropout_prob\"):\n",
    "        model.config.attention_probs_dropout_prob = 0.10\n",
    "    if hasattr(model.config, \"use_cache\"):\n",
    "        model.config.use_cache = False\n",
    "\n",
    "\n",
    "    args = TrainingArguments(\n",
    "        output_dir=PSEUDO_DIR,\n",
    "        learning_rate=2e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=8,\n",
    "        gradient_accumulation_steps=4,\n",
    "        num_train_epochs=4,\n",
    "        warmup_ratio=0.1,\n",
    "        weight_decay=0.01,\n",
    "        max_grad_norm=1.0,\n",
    "        lr_scheduler_type=\"cosine\",\n",
    "        eval_strategy=\"steps\",\n",
    "        eval_steps=1500,\n",
    "        save_strategy=\"steps\",\n",
    "        save_steps=1500,\n",
    "        save_total_limit=1,\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1_weighted\",\n",
    "        greater_is_better=True,\n",
    "        fp16=True,\n",
    "        logging_steps=200,\n",
    "        report_to=\"none\",\n",
    "        dataloader_num_workers=2,\n",
    "        save_safetensors=True,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=tr_ds,\n",
    "        eval_dataset=val_ds,\n",
    "        data_collator=collator,\n",
    "        compute_metrics=compute_metrics_eval,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    # Validation logits\n",
    "    val_pred = trainer.predict(val_ds)\n",
    "    pseudo_val_logits = val_pred.predictions\n",
    "    y_true_val = val_df[\"labels\"].values\n",
    "    y_pred_val = pseudo_val_logits.argmax(axis=-1)\n",
    "\n",
    "    print(\"\\n=== PSEUDO-FINAL MODEL Validation Metrics ===\")\n",
    "    print(f\"Accuracy     : {accuracy_score(y_true_val, y_pred_val):.4f}\")\n",
    "    print(f\"F1 Weighted  : {f1_score(y_true_val, y_pred_val, average='weighted'):.4f}\")\n",
    "    print(f\"F1 Macro     : {f1_score(y_true_val, y_pred_val, average='macro'):.4f}\")\n",
    "    print(\"\\n\", classification_report(y_true_val, y_pred_val, target_names=EMOTIONS, digits=4))\n",
    "\n",
    "    np.save(pseudo_val_logits_path, pseudo_val_logits)\n",
    "    print(f\"[INFO] Saved pseudo val logits to: {pseudo_val_logits_path}\")\n",
    "\n",
    "    # Test logits\n",
    "    test_pred = trainer.predict(hf_test)\n",
    "    pseudo_test_logits = test_pred.predictions\n",
    "    np.save(pseudo_test_logits_path, pseudo_test_logits)\n",
    "    print(f\"[INFO] Saved pseudo test logits to: {pseudo_test_logits_path}\")\n",
    "\n",
    "    # cleanup\n",
    "    del model, trainer, tr_ds, val_ds, val_pred, test_pred\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# STEP D: Final ensemble (CV5 + Pseudo-final) & submission\n",
    "\n",
    "print(\"\\n[STEP D] Final ensemble & submission...\")\n",
    "\n",
    "# Ensure shapes\n",
    "assert cv5_test_logits.shape == pseudo_test_logits.shape, \\\n",
    "    f\"Shape mismatch: cv5={cv5_test_logits.shape}, pseudo={pseudo_test_logits.shape}\"\n",
    "\n",
    "final_logits = ALPHA_CV5 * cv5_test_logits + (1.0 - ALPHA_CV5) * pseudo_test_logits\n",
    "final_pred_ids = final_logits.argmax(axis=-1)\n",
    "final_pred_labels = [id2label[i] for i in final_pred_ids]\n",
    "\n",
    "sub_df = pd.DataFrame({\n",
    "    \"id\": df_test[\"id\"].values,\n",
    "    \"emotion\": final_pred_labels,\n",
    "})\n",
    "\n",
    "sub_path = \"final_submission.csv\"\n",
    "sub_df.to_csv(sub_path, index=False)\n",
    "print(f\"\\n[INFO] Saved FINAL submission to: {sub_path}\")\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DMLab2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
